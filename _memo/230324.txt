딥러닝에서 RNN 쓴다면 대부분 LSTM 쓴다


마지막에는 코끼리의 Shape가 맞아야겠지
LSTM 3차원_batch, timesteps(input_leneth), feature(input_dim)

slicing 시계열부터는 y값이 없다 알아서 잘라야한다
개발자 또는 오너가 정할 수 있다
단순반복

LSTM/ DNN 좋은거 쓰면 된다
DNN > LSTM도 Shape만 맞춰주면 가능하다

주가 데이터를 받는다면 몇개씩 훈련시킬 것인가?


labeling 한명한테 몰빵하면 안된다..
red wine인지 white wine인지 구분할 수 있겠지?

보스턴 컬럼 13개,
(n, 13) > (n, 13, 1)

RNN을 양쪽으로?
Bidirectional RNN을 랩핑한다

///////////////////////////////
시험
주가 데이터 주고
월요일 또는 화요일 아침 시가 또는 종가?를 맞추는거

///////////////////////////////
4차원 행: 가로 세로 칼러 - 행, 엔빵, 컬러

FLATTEN한 건 CONV1D라 한다
Timeseries data(시계열 데이터)

rnn이 conv보다 연산량이 더 많다
그래서 논문에 lstm은 죽었다라고 나온다?

cov1이 빠르다 1차원데이터에서 특성을 뽑아서 쓰기 때문에
con1 2와 사용법은 같다 